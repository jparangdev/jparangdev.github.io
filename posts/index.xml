<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>Posts on Jparagdev&#39;s blog</title>
        <link>/posts/</link>
        <description>Recent content in Posts on Jparagdev&#39;s blog</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>en-us</language>
        <lastBuildDate>Mon, 01 Feb 2021 21:23:00 +0900</lastBuildDate>
        <atom:link href="/posts/index.xml" rel="self" type="application/rss+xml" />
        
        <item>
            <title>Event-driven이 뭐지?</title>
            <link>/posts/programming/event-driven/</link>
            <pubDate>Mon, 01 Feb 2021 21:23:00 +0900</pubDate>
            
            <guid>/posts/programming/event-driven/</guid>
            <description>간간이 기술 블로그나 유튜브를 보다 보면 Event-Driven Programming , Event-Driven Architecture 등등 Event-Driven이라는 단어가 많이 보인다. 대충 어림짐작으로 생각했을 때는 비동기적으로 처리되는 이벤트들을 실시간으로 잘 처리 해주는 것이 이벤트 드리븐이 아닐까? 라는 생각을 했다.
이번 포스팅으로 스스로 정리하는 시간을 가지려 한다. 먼저 wikipedia 를 찾아봤다.
Event-driven architecture
Event-driven architecture (EDA) is a software architecture paradigm promoting the production, detection, consumption of, and reaction to events.
이벤트 드리븐 아키텍쳐란 이벤트를 중심으로 생산,감지,소비,반응을 촉진하는 소프트웨어 패러다임이라 한다.</description>
            <content type="html"><![CDATA[<p>간간이 기술 블로그나 유튜브를 보다 보면 Event-Driven Programming , Event-Driven Architecture 등등 Event-Driven이라는 단어가 많이 보인다.
대충 어림짐작으로 생각했을 때는 비동기적으로 처리되는 이벤트들을 실시간으로 잘 처리 해주는 것이 이벤트 드리븐이 아닐까? 라는 생각을 했다.</p>
<p>이번 포스팅으로 스스로 정리하는 시간을 가지려 한다.
먼저 wikipedia 를 찾아봤다.</p>
<p>Event-driven architecture<br>
Event-driven architecture (EDA) is a software architecture paradigm promoting the production, detection, consumption of, and reaction to events.</p>
<p>이벤트 드리븐 아키텍쳐란 이벤트를 중심으로 생산,감지,소비,반응을 촉진하는 소프트웨어 패러다임이라 한다.</p>
<p>Event-driven programming<br>
In computer programming, event-driven programming is a programming paradigm in which the flow of the program is determined by events such as user actions (mouse clicks, key presses), sensor outputs, or message passing from other programs or threads.</p>
<p>이벤트 드리븐 프로그래밍은 프로그램의 흐름이 사용자의 액션이나, 센서의 정보, 다른 프로그램이나 쓰레드로 부터오는 메세지의 전달로 결정되는 프로그래밍 패러다임이다.</p>
<p>두 단어 모두 이벤트가 중심이 되는 걸 알 수 있다. 그럼 정확히 프로그래밍에서 말하는 이벤트는 무엇일까? 
나는 일상적으로 서프라이즈 이벤트나 프로모션 이벤트가 먼저 연상된다. 여기서 말하는 이벤트와는 사뭇 다른 느낌이긴 하다.
프로그래밍에서 말하는 이벤트는</p>
<ol>
<li>
<p>사용자의 액션, 즉 작게는 마우스의 클릭이나 키보드의 입력부터 주문결제나 회원가입 등등 사용자가 서비스에 하는 행위</p>
</li>
<li>
<p>프로그램과 프로그램 사이 또는 프로세서 사이에서 일어나는 메세지 교환</p>
</li>
<li>
<p>외부기기로부터 발생하는 데이터를 전달받는 것</p>
</li>
</ol>
<p>이 외에 여러 가지 이벤트가 있겠지만 내가 생각했던 이벤트의 비슷한 건 하나 있다.
&lsquo;순차적으로 일어나지 않고 어느 순간 갑자기 발생한다는 것&rsquo;
아마 통신환경과 컴퓨팅기술의 발전에 따라 다양하고 복잡한 이벤트가 동시에 일어나는 경우가 많아지고 트래픽이 증가하여 이에 대응하는 방법으로 비동기 처리에 유리한 이벤트 드리븐 방식이 주목받지 않았나 싶다.</p>
<p>그럼 이러한 이벤트 드리븐 방식이 어떻게 구현되어 사용되고 있는지 알아보자
먼저 이벤트 드리븐 아키텍쳐의 예로 NodeJs가 대표적이다.</p>
<figure>
    <img src="/images/programming/event-driven.png"
         alt="hugo complete"/> <figcaption>
            <p><a href="https://diophant.com/blog/mitigating-node-js-event-loop-saturation">https://diophant.com/blog/mitigating-node-js-event-loop-saturation</a></p>
        </figcaption>
</figure>

<p>Node Js는 위와 같이 발생하는 이벤트들을 이벤트 루프를 돌며 스레드에 각각 분배하여 이벤트를 처리하는 방식으로 구성되어 있다. (I/O 등 커널을 사용해야하는 이벤트는 제외)<br>
Event-Driven Programming 도 동일하게 하나의 이벤트 리스너를 두고 멀티스레드에 분배하는 방식인 듯하나 나중에 자신이 코딩하게 되거나 좋은 코드를 보게 되면 이 글에 추가하도록 하겠다</p>
<p>이벤트 드리븐 방식은 다양한 트레픽에 비동기 식으로 대응하기에 적합한 패러다임이고 Kafka, Spring Webflux, NodeJs, Nginx 등 다양한 프레임워크에서도 채택하였다.<br>
이런 프레임 워크들은 성능적으로도 주목받고 있다. 나는 아직 실무 프로젝트에서 사용하며 체감해보지 못했지만 먼저 개념적으로 익숙해지고 준비해 나가는게 좋을 것 같다.</p>
<p>참고<br>
<a href="https://news.samsung.com/kr/%EC%9A%94%EC%A6%98-%EC%A0%9C%EC%9D%BC-%ED%95%AB%ED%95%98%EB%8B%A4%EB%8A%94-%EC%9D%B4%EB%B2%A4%ED%8A%B8-%EB%93%9C%EB%A6%AC%EB%B8%90-%EB%88%84%EA%B5%AC%EB%83%90-%EB%84%8C">https://news.samsung.com/kr/요즘-제일-핫하다는-이벤트-드리븐-누구냐-넌</a><br>
<a href="https://en.wikipedia.org/wiki/Event-driven_architecture">https://en.wikipedia.org/wiki/Event-driven_architecture</a><br>
<a href="https://en.wikipedia.org/wiki/Event-driven_programming">https://en.wikipedia.org/wiki/Event-driven_programming</a></p>
]]></content>
        </item>
        
        <item>
            <title>Kafka 알아보기 - 2</title>
            <link>/posts/kafka/about-kafka-2/</link>
            <pubDate>Sun, 10 Jan 2021 14:22:00 +0900</pubDate>
            
            <guid>/posts/kafka/about-kafka-2/</guid>
            <description>그럼 이제 실제로 카프카를 한번 설치해보자
Kafka Download URL : https://kafka.apache.org/downloads
$ mkdir kafka $ cd kafka $ wget https://downloads.apache.org/kafka/2.6.0/kafka_2.12-2.6.0.tgz $ tar -zxvf kafka_2.12-2.6.0.tgz Kafka를 다운로드 받고 압축을 해제.
압축을 해제한 폴더의 Config폴더로 들어가면 zookeeper.properties 파일이 있다.
Kafka의 메타데이터 관리는 zookeeper가 관리하기 때문에 해당 파일을 통해 설정을 변경 할 수 있다.
$ cd kafka_2.12-2.6.0 $ mkdir data $ echo 1 &amp;gt; myid $ vi myid 미리 zookeeper의 데이터(각 ID)가 저장될 폴더를 생성하자</description>
            <content type="html"><![CDATA[<p>그럼 이제 실제로 카프카를 한번 설치해보자</p>
<p>Kafka Download URL : <a href="https://kafka.apache.org/downloads">https://kafka.apache.org/downloads</a></p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">$ mkdir kafka
$ cd kafka
$ wget https://downloads.apache.org/kafka/2.6.0/kafka_2.12-2.6.0.tgz
$ tar -zxvf kafka_2.12-2.6.0.tgz
</code></pre></div><p>Kafka를 다운로드 받고 압축을 해제.<br>
압축을 해제한 폴더의 Config폴더로 들어가면 zookeeper.properties 파일이 있다.<br>
Kafka의 메타데이터 관리는 zookeeper가 관리하기 때문에 해당 파일을 통해 설정을 변경 할 수 있다.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">$ cd kafka_2.12-2.6.0
$ mkdir data
$ echo <span style="color:#ae81ff">1</span> &gt; myid
$ vi myid
</code></pre></div><p>미리 zookeeper의 데이터(각 ID)가 저장될 폴더를 생성하자<br>
/app/kafka/kafka-2.6.0-src/data 에 생성</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell"><span style="color:#75715e"># Licensed to the Apache Software Foundation (ASF) under one or more</span>
<span style="color:#75715e"># contributor license agreements.  See the NOTICE file distributed with</span>
<span style="color:#75715e"># this work for additional information regarding copyright ownership.</span>
<span style="color:#75715e"># The ASF licenses this file to You under the Apache License, Version 2.0</span>
<span style="color:#75715e"># (the &#34;License&#34;); you may not use this file except in compliance with</span>
<span style="color:#75715e"># the License.  You may obtain a copy of the License at</span>
<span style="color:#75715e">#</span>
<span style="color:#75715e">#    http://www.apache.org/licenses/LICENSE-2.0</span>
<span style="color:#75715e">#</span>
<span style="color:#75715e"># Unless required by applicable law or agreed to in writing, software</span>
<span style="color:#75715e"># distributed under the License is distributed on an &#34;AS IS&#34; BASIS,</span>
<span style="color:#75715e"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>
<span style="color:#75715e"># See the License for the specific language governing permissions and</span>
<span style="color:#75715e"># limitations under the License.</span>
<span style="color:#75715e"># the directory where the snapshot is stored.</span>
<span style="color:#75715e"># 각 서버별 아이디가 저장될 위치를 지정해줍니다.</span>
dataDir<span style="color:#f92672">=</span>/app/kafka/kafka_2.12-2.6.0/data 
<span style="color:#75715e"># the port at which the clients will connect</span>
clientPort<span style="color:#f92672">=</span><span style="color:#ae81ff">2181</span>
<span style="color:#75715e"># disable the per-ip limit on the number of connections since this is a non-production config</span>
maxClientCnxns<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>
<span style="color:#75715e"># Disable the adminserver by default to avoid port conflicts.</span>
<span style="color:#75715e"># Set the port to something non-conflicting if choosing to enable this</span>
admin.enableServer<span style="color:#f92672">=</span>false
<span style="color:#75715e"># admin.serverPort=808</span>

<span style="color:#75715e"># 팔로워 파티션과 리더 파티션이 초기 연결되는 시간제한 설정 </span>
initLimit<span style="color:#f92672">=</span><span style="color:#ae81ff">5</span> 

<span style="color:#75715e"># 팔로워 파티션과 리더 파티션이 동기화 되는 시간의 타임아웃</span>
<span style="color:#75715e"># 해당시간내에 동기화 되지 않으면 해제된다.</span>
syncLimmit<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>

<span style="color:#75715e"># 각각의 Kafka Broker 서버정보</span>
juvis-kafka.1<span style="color:#f92672">=(</span>첫번째서버 IP<span style="color:#f92672">)</span>:2888:3888
juvis-kafka.2<span style="color:#f92672">=(</span>두번째서버 IP<span style="color:#f92672">)</span>:2888:3888
</code></pre></div><p>dataDir에 생성한 폴더 주소를 입력하고 initLimit,syncLimmit를 입력한 뒤 각 서버 정보를 입력<br>
자세한 내용은 <a href="https://zookeeper.apache.org/">https://zookeeper.apache.org/</a> 페이지를 참고하자.</p>
<p>각각의 서버에서 아까 만들었던 Data폴더 위치에 myid 파일을 만들고 여기에는 각각 아이디의 번호인 1, 2를 입력하자<br>
myid 파일에 쓰인 번호는 <a href="http://zookeeper.properties">zookeeper.properties</a> 파일에 쓰인 .1 .2의 아이디와 연결되는 역할을 한다</p>
<p>이번엔 server.properties 파일을 설정해보자.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">listeners<span style="color:#f92672">=</span>PLAINTEXT://:9092

advertised.listeners<span style="color:#f92672">=</span>PLAINTEXT://192.168.137.101:9092

zookeeper.connect<span style="color:#f92672">=(</span>첫번째 서버 IP<span style="color:#f92672">)</span>:2181, <span style="color:#f92672">(</span>두번째 서버 IP<span style="color:#f92672">)</span>:2181, 
</code></pre></div><p>방화벽도 해재한다.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell"><span style="color:#75715e">## 주키퍼 포트 </span>
firewall-cmd --permanent --zone<span style="color:#f92672">=</span>public --add-port<span style="color:#f92672">=</span>2181/tcp
firewall-cmd --permanent --zone<span style="color:#f92672">=</span>public --add-port<span style="color:#f92672">=</span>2888/tcp
firewall-cmd --permanent --zone<span style="color:#f92672">=</span>public --add-port<span style="color:#f92672">=</span>3888/tcp

<span style="color:#75715e">## 카프카 포트</span>
firewall-cmd --permanent --zone<span style="color:#f92672">=</span>public --add-port<span style="color:#f92672">=</span>9092/tcp
</code></pre></div><p>앞서 진행한 작업들은 각 서버마다 연동을 해주기 위한 기본적인 작업이다.
이제 Zookeeper를 먼저 구동후 Kafka를 구동해보자</p>
<p>기동하려는데 에러 발생.. 원인은 소스파일이아니라 바이너리 파일을 받았어야함..ㅠ
다시 수정해서 위에 진행사항과 동일하게 진행했다.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">Classpath is empty. Please build the project first e.g. by running <span style="color:#e6db74">&#39;./gradlew jar -PscalaVersion=2.13.2&#39;</span>
</code></pre></div><p>이런 오류가 뜬다&hellip;</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">$ bin/zookeeper-server-start.sh config/zookeeper.properties
$ bin/kafka-server-start.sh config/server.properties
</code></pre></div><p>zookeeper를 먼저 기동하고 kafka를 기동해야 한다.</p>
]]></content>
        </item>
        
        <item>
            <title>Kafka 알아보기 - 1</title>
            <link>/posts/kafka/about-kafka-1/</link>
            <pubDate>Sat, 02 Jan 2021 21:43:00 +0900</pubDate>
            
            <guid>/posts/kafka/about-kafka-1/</guid>
            <description>1. What is Kafka ?   https://www.confluent.io/blog/kafka-fastest-messaging-system
  Apache Kafka is an evnet streaming platform Kafka는 오픈소스 분산메세지 플랫폼이다. 실시간으로 대량의 스트림(메세지)를 처리하는데 적합한 Messaging Queue(MQ)의 일종 Kafka는 대용량의 메세지 처리가 필요한 링크드인에서 개발해 2011년 아파치의 공식 오픈소스로 공개되었다. 다른 분산 메세징 시스템에 비해 비교적 우수한 성능을 보여주어, 현재 많은 기업에서 사용중이라고 한다.
2. Kafka Process   Kafka의 기본 구조
  Kafka는 기본적으로 Publish/Subscribe 구조를 사용한다. Producer가 메세지를 발행(Publish)하면 Topic을 구독(Subscribe)하는 Consumer가 메세지를 소비하는 구조 거기에 Broker(Kafka)가 둘 사이를 중계하며 메세지를 효율적으로 전달하는 역할을 한다.</description>
            <content type="html"><![CDATA[<h2 id="1-what-is-kafka-">1. What is Kafka ?</h2>
<figure>
    <img src="/images/kafka/about-kafka-fastest.png"
         alt="kafka process - 1"/> <figcaption>
            <p><a href="https://www.confluent.io/blog/kafka-fastest-messaging-system">https://www.confluent.io/blog/kafka-fastest-messaging-system</a></p>
        </figcaption>
</figure>

<h4 id="apache-kafka-is-an-evnet-streaming-platform">Apache Kafka is an evnet streaming platform</h4>
<p>Kafka는 오픈소스 분산메세지 플랫폼이다.
실시간으로 대량의 스트림(메세지)를 처리하는데 적합한 Messaging Queue(MQ)의 일종
Kafka는 대용량의 메세지 처리가 필요한 링크드인에서 개발해 2011년 아파치의 공식 오픈소스로 공개되었다.
다른 분산 메세징 시스템에 비해 비교적 우수한 성능을 보여주어, 현재 많은 기업에서 사용중이라고 한다.</p>
<h2 id="2-kafka-process">2. Kafka Process</h2>
<figure>
    <img src="/images/kafka/about-kafka-process.png"
         alt="kafka process - 1"/> <figcaption>
            <p>Kafka의 기본 구조</p>
        </figcaption>
</figure>

<p>Kafka는 기본적으로 Publish/Subscribe 구조를 사용한다.
Producer가 메세지를 발행(Publish)하면 Topic을 구독(Subscribe)하는 Consumer가 메세지를 소비하는 구조
거기에 Broker(Kafka)가 둘 사이를 중계하며 메세지를 효율적으로 전달하는 역할을 한다.
이렇게 각각 독립적으로 기능을 수행하며 서로 연결되어 있는 구성을 느슨한 결합(Loosely Coupled)이라 한다.</p>
<p>다수의 Producer가 데이터를 메세지화 하여 전송하면 Kafka가 <a href="/posts/programming/event-driven/">Event-Driven</a> 방식으로 대량의 메세지를 병렬적으로 처리하며 해당 Topic을 구독하고있는 Consumer에게 전송하게 된다.</p>
<h2 id="3-kafka-component">3. Kafka Component</h2>
<figure>
    <img src="/images/kafka/about-kafka-component.png"
         alt="kafka Component - 1"/> <figcaption>
            <p><em>Kafka의 구성요소</em></p>
        </figcaption>
</figure>

<p>Kafak의 기본적인 구성요소들을 하나씩 살펴보면</p>
<ul>
<li>
<p><strong>Topic</strong>
메세지의 종류 또는 카테고리이다. Producer가 특정 Topic으로 메세지를 생성하면, 이 Topic을 구독하고 있는 Consumer는 메세지를 소비한다.</p>
</li>
<li>
<p><strong>Partition</strong><br>
Topic 내에서 메세지가 분산되어 저장되는 Queue. 하나의 Topic에 단일 Partition인 경우 순서가 보장 될 수 있으나, 다중 Partition인 경우 각 Partition의 끝에서 Round-Robin 방식으로 쓰여지기 때문에 읽어 올 때 그 순서를 보장 할 수 없다.  Topic내 Partition 수는 설정이 가능하며은 한번 늘리면 다시 줄일 수 없음.</p>
</li>
<li>
<p><strong>Log</strong><br>
Partition의 한 메세지 부분</p>
</li>
<li>
<p><strong>Broker</strong><br>
Kafka의 서버를 의미한다. Broker 여러개가 Cluster를 구성하며, Zookeeper를 통해 메타데이터를 공유</p>
</li>
<li>
<p><strong>Zookeeper</strong><br>
Kafka의 메타정보를 관리하는 프로그램 Zookeeper가 실행되어야 Kafka가 실행 될 수 있다.</p>
</li>
</ul>
<h2 id="4-topic--partition">4. Topic &amp; Partition</h2>
<figure>
    <img src="/images/kafka/about-kafka-partition.png"
         alt="kafka partiton"/> <figcaption>
            <p><em>이미치 출처 : <a href="https://medium.com/@umanking/%EC%B9%B4%ED%94%84%EC%B9%B4%EC%97%90-%EB%8C%80%ED%95%B4%EC%84%9C-%EC%9D%B4%EC%95%BC%EA%B8%B0-%ED%95%98%EA%B8%B0%EC%A0%84%EC%97%90-%EB%A8%BC%EC%A0%80-data%EC%97%90-%EB%8C%80%ED%95%B4%EC%84%9C-%EC%9D%B4%EC%95%BC%EA%B8%B0%ED%95%B4%EB%B3%B4%EC%9E%90-d2e3ca2f3c2">https://medium.com/@umanking/%EC%B9%B4%ED%94%84%EC%B9%B4%EC%97%90-%EB%8C%80%ED%95%B4%EC%84%9C-%EC%9D%B4%EC%95%BC%EA%B8%B0-%ED%95%98%EA%B8%B0%EC%A0%84%EC%97%90-%EB%A8%BC%EC%A0%80-data%EC%97%90-%EB%8C%80%ED%95%B4%EC%84%9C-%EC%9D%B4%EC%95%BC%EA%B8%B0%ED%95%B4%EB%B3%B4%EC%9E%90-d2e3ca2f3c2</a></em></p>
        </figcaption>
</figure>

<p>Producer와 Consumer는 하나의 Topic으로 메세지를 주고 받게 된다.
Topic은 하나 이상의 Partition으로 이루어지게 되는데 이는 많은 메세지를 처리하기 위해 비동기적으로 작동한다.
다수의 Producer는 각각의 Partition에 순차적으로 데이터를 쌓게 되며 Consumer (ConsumerGroup)은 각각의 partition의 offset에 따라 데이터를 구독한다.</p>
<figure>
    <img src="/images/kafka/about-kafka-partition-2.png"
         alt="kafka partiton-2"/> <figcaption>
            <p><em>이미치 출처 : <a href="https://engkimbs.tistory.com/691">https://engkimbs.tistory.com/691</a></em></p>
        </figcaption>
</figure>

<h2 id="5-consumergroup">5. ConsumerGroup</h2>
<p>Consumer Group은 Consumer서버의 모임이라 할 수 있다.
각 ConsumerGroup은 하나의 Topic만 구독한다.
Topic은 여러개의 Consumer Group과 연결되며 Consumer Group은 Consumer 끼리 Topic의 최종 offset을 공유하는 그룹이다.
하나의 Consumer가 이상이 생겼을 경우 나머지 Consumer가 동일하게 메세지를 소비한다.</p>
<p>Consumer Group의 각 Consumer의 숫자에 따라 Partition에 접근하는 방법도 다르다.
Consumer Group안의 Consumer수와 Partition 수가 같은 경우 1:1로 매칭되어 각 Partition의 데이터를 가져오지만 
Consumer가 더 많은 경우 남은 Consumer는 Partition이 늘어날 때까지 대기하게 되며 Partition 숫자가 더 많아지는 경우는 Consumer가 여러개의 partition의 Message를 소비하게 된다.</p>
<figure>
    <img src="/images/kafka/kafak-counsumer-group.png"
         alt="kafka consumer group"/> <figcaption>
            <p><em>이미치 출처 : <a href="https://www.popit.kr/kafka-consumer-group">https://www.popit.kr/kafka-consumer-group</a></em></p>
        </figcaption>
</figure>

<p>하나의 서버가 장애가 생긴경우 ConsumerGroup 에 포함된 다른서버에서는 메세지를 동일 하게 소모 할 수 있다.</p>
<figure>
    <img src="/images/kafka/kafak-counsumer-group-2.png"
         alt="kafka consumer group - 2"/> 
</figure>

<p>참고<br>
<a href="https://kafka.apache.org/intro">https://kafka.apache.org/intro</a><br>
<a href="https://victorydntmd.tistory.com/344">https://victorydntmd.tistory.com/344</a><br>
<a href="https://taetaetae.github.io/2017/11/02/what-is-kafka/">https://taetaetae.github.io/2017/11/02/what-is-kafka/</a><br>
<a href="https://epicdevs.com/17">https://epicdevs.com/17</a><br>
<a href="https://engkimbs.tistory.com/691">https://engkimbs.tistory.com/691</a></p>
]]></content>
        </item>
        
        <item>
            <title>github.io 블로그 만들기 - 2</title>
            <link>/posts/blog/hugo-2/</link>
            <pubDate>Tue, 22 Dec 2020 21:00:00 +0900</pubDate>
            
            <guid>/posts/blog/hugo-2/</guid>
            <description>이전 블로그에 이어 이번엔 테마를 설정해보도록 하겠다.
https://themes.gohugo.io/tags/blog/
위 페이지에 접속하여 원하는 테마를 골라보도록 하자. 일반적으로 모든 테마에서는 설치법과 기본적인 사용법이 개발자분들이 적어 놓은 경우가 많아 이를 참고하는것이 좋긴하다.
일단 내가 적용했던 방법을 기록해본다.
간편하게 생성했던 프로젝트 파일 themes 아래 서브모듈로 추가하거나 (테마제작자의 업데이트가 상관없는경우 가능)
$ git clone &amp;lt;테마 Git주소&amp;gt; themes/&amp;lt;테마이름&amp;gt; $ git submodule add &amp;lt;테마 Git주소&amp;gt; themes/&amp;lt;테마이름&amp;gt; 아니면 직접 다운받아 themes폴더 아래에 위치시켜주면 된다.
이후 config.toml파일을 각 테마에 맞게 수정해줘야한다.</description>
            <content type="html"><![CDATA[<p>이전 블로그에 이어 이번엔 테마를 설정해보도록 하겠다.</p>
<p><a href="https://themes.gohugo.io/tags/blog/">https://themes.gohugo.io/tags/blog/</a></p>
<p>위 페이지에 접속하여 원하는 테마를 골라보도록 하자. 
일반적으로 모든 테마에서는 설치법과 기본적인 사용법이 개발자분들이 적어 놓은 경우가 많아 이를 참고하는것이 좋긴하다.</p>
<p>일단 내가 적용했던 방법을 기록해본다.</p>
<p>간편하게 생성했던 프로젝트 파일 themes 아래 서브모듈로 추가하거나 (테마제작자의 업데이트가 상관없는경우 가능)</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">$ git clone &lt;테마 Git주소&gt; themes/&lt;테마이름&gt;
$ git submodule add &lt;테마 Git주소&gt; themes/&lt;테마이름&gt;
</code></pre></div><p>아니면 직접 다운받아 themes폴더 아래에 위치시켜주면 된다.</p>
<p>이후 config.toml파일을 각 테마에 맞게 수정해줘야한다. 
테마별 사이트에 자세히 나와있어 맞게 수정하면 되며, 기본적으로 baseURL, Theme, Title 정도는 기본으로 설정해야 한다.</p>
<p>이제 시험삼아 Post를 하나 생성해보도록 하자</p>
<p>Hugo는 Content 아래의 폴더가 게시글이 되도록 기본적으로 설정되어 있다. 
나는 주제에 맞춰 혹은 시리즈에 맞춰 폴더를 생성하고 그아래 .md 파일을 하나 생성해서 글을 작성했다.</p>
<p>테마도 적용되었는지 확인하고 글도 잘올라갔는지 확인하려면 먼저 내컴퓨터에서 홈페이지를 기동해봐야한다. 
Intellij같은 툴을 쓰는경우 환경 설정을 통해 쉽게 본인 PC에 서버를 올릴 수 있고 shell을 통해 기동도 가능하다.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">$ hugo server -D
</code></pre></div><figure>
    <img src="/images/hugo/hugo-4.png"
         alt="hugo server"/> <figcaption>
            <p>해당화면처럼 빌드가 되면 가능</p>
        </figcaption>
</figure>

<p>이제 localhost:1313번에 접속해서 자신의 블로그를 확인해보도록 하자</p>
]]></content>
        </item>
        
        <item>
            <title>github.io 블로그 만들기 - 1</title>
            <link>/posts/blog/hugo-1/</link>
            <pubDate>Thu, 17 Dec 2020 20:45:00 +0900</pubDate>
            
            <guid>/posts/blog/hugo-1/</guid>
            <description>기록은 힘이다 말이 있듯이 자신만의 지식 아카이브를 만들어 두는 것은 큰 도움이 된다. 다른사람에게 정보 전달의 목적도 있지만 나 자신의 생각을 정리하기 위해 블로그를 기록하기로 한다.
github는 간편하면서 무료로 호스팅을 한다. 다만, 정적인 페이지로만 생성이 가능
내가 만들 블로그의 경우는 방문자에게 정보 전달만이 목적이기에 Static Website로 구성 현재는 많은 개발자분들이 Github를 통해 블로그를 구축하는듯 하다
먼저 블로그를 구축하기전에 Git에 대한 기본적이 지식이 필요하다. Git에 대한 정보는 이미 웹에 많은 좋은 기록이 많기 때문에 따로 다루진 않는다.</description>
            <content type="html"><![CDATA[<p>기록은 힘이다 말이 있듯이 자신만의 지식 아카이브를 만들어 두는 것은 큰 도움이 된다.
다른사람에게 정보 전달의 목적도 있지만 나 자신의 생각을 정리하기 위해 블로그를 기록하기로 한다.</p>
<p>github는 간편하면서 무료로 호스팅을 한다. 다만, 정적인 페이지로만 생성이 가능</p>
<p>내가 만들 블로그의 경우는 방문자에게 정보 전달만이 목적이기에 Static Website로 구성
현재는 많은 개발자분들이 Github를 통해 블로그를 구축하는듯 하다</p>
<p>먼저 블로그를 구축하기전에 Git에 대한 기본적이 지식이 필요하다.
Git에 대한 정보는 이미 웹에 많은 좋은 기록이 많기 때문에 따로 다루진 않는다.
대신 Opentutorials의 강의를 링크한다.<br>
<a href="https://opentutorials.org/course/2708">https://opentutorials.org/course/2708</a></p>
<p>나는 Hugo를 사용하여 블로그를 구성하기로 했다. 
Github.io에 Jekyll가 대표적이지만,
Jekyll에 비해 빌드속도가 빠르다는 점과 Go 언어를 사용한다는점이 매력적이라 생각해서 Hugo를 선택!</p>
<p>비록 Jekyll에 비해 메뉴얼도 템플릿도 부족한 듯 싶으나 일단 Hugo를 사용하기로 맘먹고 시작해보았다.
Hugo에 마음에 드는 테마가 있던 것도 한 몫했다.</p>
<p>먼저 Hugo는 <a href="https://gohugo.io/getting-started/installing/">https://gohugo.io/getting-started/installing/</a> 에서 OS별 설치 방법을 알 수 있고 
Git (<a href="https://github.com/gohugoio/hugo">https://github.com/gohugoio/hugo</a>) 에서 최신 Hugo를 다운받아 사용이 가능하다. OS는 Window 10에서 진행하였다.</p>
<p>Hugo를 다운받았다면 원하는 위치에서 압축을 풀고 bin폴더 안의 hugo.exe의 환경변수를 설정해주도록 한다.
<figure>
    <img src="/images/hugo/hugo-1.png"
         alt="hugo setting path"/> <figcaption>
            <p>윈도우의 시스템 환경설정</p>
        </figcaption>
</figure>
</p>
<p>이후 cmd를 통해 Hugo가 제대로 작동하는 지 확인한다.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">    $ hugo version
</code></pre></div><p>다음과 같은 화면이 나온다면 정상적으로 작동 된 것
<figure>
    <img src="/images/hugo/hugo-2.png"
         alt="hugo install"/> <figcaption>
            <p>Hugo 버전확인</p>
        </figcaption>
</figure>
</p>
<p>이제 블로그용 소스를 만들 위치에 hugo site파일을 만들어보도록 하자</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">    $ hugo new site C:<span style="color:#ae81ff">\j</span>aprangev<span style="color:#ae81ff">\t</span>estsite
</code></pre></div><p>해당 메세지가 출력되고 파일이 잘 생성된 것을 확인하였으면 기본적인 블로그 사이트 소스 생성이 된 것이다.</p>
<figure>
    <img src="/images/hugo/hugo-3.png"
         alt="hugo complete"/> <figcaption>
            <p>간략하게 테마적용법과 구동방법이 나온다</p>
        </figcaption>
</figure>

<p>다음으로 Git을 통해 형상관리가 가능하도록 원격 git을 연결하도록 하자
먼저 <a href="https://github.com">https://github.com</a> 으로 접속하여 저장소를 2개 생성해야한다.</p>
<ol>
<li>블로그 소스용 저장소</li>
<li>블로그가 게시될 Github.io 용 저장소</li>
</ol>
<p>new site로 생성한 블로그 소스를 원격 저장소에 연결해보자.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">    $ cd C:<span style="color:#ae81ff">\j</span>aprangev<span style="color:#ae81ff">\t</span>estsite
    $ git init
    $ git add .
    $ git commit -m <span style="color:#e6db74">&#34;first commit&#34;</span>
    $ git branch -M main
    $ git remote add origin https://github.com/jparangdev/testsite-src.git
    $ git push -u origin main
</code></pre></div><p>github에 접속해 해당 소스가 제대로 푸쉬가 되었는지 확인</p>
<p>여기까지 글을 마치고 다음에 테마를 연결해보자~~~~</p>
]]></content>
        </item>
        
    </channel>
</rss>
